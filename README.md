# Book Data API üìö

Este reposit√≥rio cont√©m o c√≥digo-fonte de uma API RESTful para consulta de dados de livros, desenvolvida como parte de um Tech Challenge. A solu√ß√£o inclui um pipeline de dados completo, desde a extra√ß√£o (web scraping), passando pelo carregamento em um banco de dados, at√© a disponibiliza√ß√£o dos dados atrav√©s de endpoints seguros e bem documentados.

## üèõÔ∏è Arquitetura

O projeto √© estruturado como um pipeline de dados desacoplado que alimenta uma API. O fluxo principal √©:

`[Fonte Web] -> [1. Extra√ß√£o] -> [2. Armazenamento Intermedi√°rio] -> [3. Carregamento] -> [4. Banco de Dados] -> [5. API] -> [6. Cliente]`

![Diagrama da Arquitetura](arquitetura.png)

## ‚ú® Features

* **Pipeline de Dados Robusto:** Scripts separados para extra√ß√£o (`scrape`) e carregamento (`load`), com modo de continua√ß√£o (`--append`) para resili√™ncia.
* **Banco de Dados Versionado:** Uso de **SQLAlchemy** como ORM e **Alembic** para gerenciar as migra√ß√µes do schema, garantindo consist√™ncia entre ambientes.
* **API Moderna:** Constru√≠da com **FastAPI**, com schemas de valida√ß√£o **Pydantic** e documenta√ß√£o interativa autom√°tica (Swagger UI).
* **Autentica√ß√£o Segura:** Implementa√ß√£o de autentica√ß√£o via **JWT** com endpoints para cria√ß√£o de usu√°rios e login.
* **Qualidade de C√≥digo:** Formata√ß√£o e linting garantidos por **Ruff** e **Black**.
* **Logging Estruturado:** Logs separados para o pipeline de dados (`ingestion.log`) e para a API (`api.log`), facilitando a depura√ß√£o e monitoramento.

## üõ†Ô∏è Tecnologias Utilizadas

* **Python 3.13+**
* **Poetry** para gerenciamento de depend√™ncias.
* **FastAPI** como framework web.
* **Uvicorn** como servidor ASGI.
* **SQLAlchemy** como ORM.
* **Alembic** para migra√ß√µes de banco de dados.
* **Pydantic** para valida√ß√£o de dados.
* **Ruff** e **Black** para qualidade de c√≥digo.
* **HTTPX** e **BeautifulSoup4** para web scraping.

## üöÄ Setup e Instala√ß√£o

Siga os passos abaixo para configurar o ambiente de desenvolvimento.

### Pr√©-requisitos
* **Git**
* **Python 3.13** (recomend√°vel gerenciar com `pyenv`)
* **Poetry**

### Passos de Instala√ß√£o

1.  **Clone o Reposit√≥rio:**
    ```bash
    git clone https://github.com/diunkz/book-data-api
    cd book-data-api
    ```

2.  **Configure o Ambiente Python:**
    Se estiver usando `pyenv`, defina a vers√£o local (opcional, mas recomendado).
    ```bash
    pyenv local 3.13.2
    ```

3.  **Instale as Depend√™ncias:**
    O Poetry ir√° ler o `pyproject.toml` e `poetry.lock` para criar um ambiente virtual e instalar todas as bibliotecas necess√°rias.
    ```bash
    poetry install
    ```

4.  **Configure as Vari√°veis de Ambiente:**
    Crie uma c√≥pia do arquivo de exemplo `.env.example` e nomeie-a `.env`. Voc√™ precisar√° criar primeiro o arquivo `.env.example`.
    ```bash
    cp .env.example .env
    ```

    **Conte√∫do para o arquivo `.env.example`:**
    ```env
    # Chave secreta para assinar os tokens JWT.
    # Em produ√ß√£o, use um valor longo e aleat√≥rio (ex: openssl rand -hex 32)
    SECRET_KEY="uma-chave-secreta-de-exemplo"

    # Algoritmo de assinatura do JWT
    ALGORITHM="HS256"

    # Tempo de expira√ß√£o do token de acesso em segundos
    ACCESS_TOKEN_EXPIRE_SECONDS=1800 # 30 minutos
    ```

## ‚öôÔ∏è Como Usar

O projeto possui tr√™s fluxos de trabalho principais: preparar o banco, popular os dados e rodar a API.

### 1. Preparar o Banco de Dados (Alembic)
Este comando l√™ os arquivos de migra√ß√£o e cria (ou atualiza) as tabelas no banco de dados. Execute-o uma vez durante o setup inicial ou ap√≥s qualquer altera√ß√£o nos modelos.

```bash
poetry run alembic upgrade head
```

### 2. Executar o Pipeline de Dados
O pipeline consiste em dois scripts que devem ser executados a partir da raiz do projeto.

**2.1. Extrair os Dados (Scraping):**
Este script raspa os dados do site e os salva em um arquivo CSV.

```bash
# Raspar todas as p√°ginas
poetry run python -m scripts.scrape_books --pages all

# Raspar p√°ginas espec√≠ficas (ex: 1 e 5)
poetry run python -m scripts.scrape_books --pages "1, 5"
```

**2.2. Carregar os Dados para o Banco:**
Este script l√™ o arquivo CSV gerado e insere os dados no banco de dados.

```bash
# Carregar o arquivo padr√£o (books_data_detailed.csv)
poetry run python -m scripts.csv_to_books_db

# Limpar a tabela e carregar os dados do zero
poetry run python -m scripts.csv_to_books_db --clear_table
```

### 3. Rodar a API
Execute o servidor web Uvicorn para iniciar a API.

```bash
poetry run uvicorn main_api:app --reload
```
* A API estar√° dispon√≠vel em `http://127.0.0.1:8000`.
* A documenta√ß√£o interativa (Swagger UI) estar√° em `http://127.0.0.1:8000/docs`.

## ‚úÖ Qualidade de C√≥digo

Este projeto utiliza o **Ruff** para linting e formata√ß√£o, garantindo um c√≥digo limpo e padronizado.

* **Para verificar o c√≥digo por erros e problemas de estilo:**
    ```bash
    poetry run ruff check .
    ```